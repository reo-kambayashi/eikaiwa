"""
Application configuration and environment setup.
ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã¨ç’°å¢ƒå¤‰æ•°ç®¡ç†

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è¨­å®šã¨ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ã€
å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆGemini AIã€TTSï¼‰ã®åˆæœŸåŒ–ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
"""

import os
from concurrent.futures import ThreadPoolExecutor

import google.generativeai as genai
from dotenv import load_dotenv

# Load environment variables from the `.env` file located at the project root.
# This allows developers to keep API keys outside of the source code for security.
# The load_dotenv() function automatically reads the .env file from the project root.
load_dotenv()

# ============================================================================
# ç’°å¢ƒå¤‰æ•°ã¨APIè¨­å®š
# ============================================================================

# API keys and credentials read from environment variables
# These are set in the .env file and loaded at runtime
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
GOOGLE_APPLICATION_CREDENTIALS = os.getenv(
    "GOOGLE_APPLICATION_CREDENTIALS", ""
)

# ============================================================================
# Gemini AI ãƒ¢ãƒ‡ãƒ«è¨­å®š
# ============================================================================

# Configure Gemini AI model for conversation generation
# The gemini-2.5-flash model provides fast, high-quality responses
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel("gemini-2.5-flash")
    # Initialize Gemini TTS model
    tts_model = genai.GenerativeModel("gemini-2.5-flash-preview-tts")
else:
    model = None
    tts_model = None

# ============================================================================
# ä¸¦è¡Œå‡¦ç†ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
# ============================================================================

# ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã‚¨ã‚°ã‚¼ã‚­ãƒ¥ãƒ¼ã‚¿ãƒ¼ã‚’è¨­å®šï¼ˆAIå‡¦ç†ã‚’éåŒæœŸåŒ–ã™ã‚‹ãŸã‚ï¼‰
executor = ThreadPoolExecutor(max_workers=4)

# ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆå˜ä¸€ãƒ¦ãƒ¼ã‚¶ãƒ¼ç”¨ã®é«˜é€ŸåŒ–ï¼‰
response_cache = {}
CACHE_TTL = 300  # 5åˆ†é–“ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥

# ============================================================================
# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†æ©Ÿèƒ½
# ============================================================================

def optimize_cache_cleanup():
    """
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œï¼ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æœ€é©åŒ–ï¼‰
    """
    import time

    current_time = time.time()
    expired_keys = []

    for key, (data, timestamp) in response_cache.items():
        if current_time - timestamp > CACHE_TTL:
            expired_keys.append(key)

    for key in expired_keys:
        del response_cache[key]

    print(f"ğŸ§¹ Cache cleanup: removed {len(expired_keys)} expired entries")


def periodic_cache_cleanup():
    """å®šæœŸçš„ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    import time
    
    while True:
        time.sleep(300)  # 5åˆ†æ¯ã«å®Ÿè¡Œ
        optimize_cache_cleanup()


# ============================================================================
# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã®é–‹å§‹
# ============================================================================

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®šæœŸå®Ÿè¡Œã™ã‚‹ãŸã‚ã®ã‚¿ã‚¹ã‚¯
import threading

# ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’é–‹å§‹
cleanup_thread = threading.Thread(target=periodic_cache_cleanup, daemon=True)
cleanup_thread.start()
